# ğŸ§  Natural Command Assistant
> **An ultra-lightweight local assistant that converts natural language into structured function calls via FunctionGemma-270M.**

![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Python: 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)
![Model: FunctionGemma](https://img.shields.io/badge/Model-FunctionGemma-orange.svg)

Natural Command Assistant simplifies the execution of complex scripts by converting your text instructions into secure function calls. Powered locally by [FunctionGemma-270M](https://huggingface.co/google/functiongemma-270m-it), it guarantees total confidentiality and deterministic execution without API fees. It is the ideal interface for making your deployment and testing tools accessible to the entire team without the risk of human error.

## ğŸ¯ Business Problem

In many technical teams:

* Scripts already exist (tests, deployments, reportsâ€¦)
* Commands are complex or poorly documented
* Only a few experts dare to execute them
* Others hesitate for fear of making a mistake

ğŸ‘‰ **Real-world consequences**:

* Wasted time
* Dependency on specific individuals
* Human errors
* Friction between Dev, QA, and Product teams

## âœ… The Solution

A **local assistant** that transforms a natural language instruction into a **structured and controlled function call**.

Example:

```text
Run unit test in dev environment
```

â¬‡ï¸

```python
run_tests(type="unit", environment="dev")
```

The AI **does not make decisions**:
It simply **structures the user's intent** to trigger an authorized action.

## ğŸ§  Why FunctionGemma?

This project uses **FunctionGemma-270M-IT (Google)**, a model designed **specifically for function calling**.

**Why this choice?**

* ğŸª¶ 270M parameters â†’ fast and lightweight
* ğŸ  **100% local** execution
* ğŸ” Structured and deterministic outputs
* ğŸ§© Specialized in transforming intent â†’ action
* ğŸ’¸ Zero API costs, no data sent externally

ğŸ‘‰ We don't need a general-purpose chatbot here; we need a **reliable and controllable tool**.

## ğŸ—ï¸ Architecture

```mermaid
flowchart TD
    U[User<br/>Natural Language] -->|Instruction| LLM[FunctionGemma<br/>270M params]
    LLM -->|Structured Function Call| R[Command Router]
    R --> T[Test Scripts]
    R --> D[Deployment]
    R --> G[Report Generation]

```

## ğŸ”’ Separation of Concerns

| Component | Role |
| --- | --- |
| LLM | Understands intent and generates a function call |
| Router | Validates and routes the call |
| Business Scripts | Executes only authorized actions |

ğŸ‘‰ The model **cannot execute arbitrary code**.

## âš™ï¸ Exposed Functions (Example)

* `run_tests(type, environment)`
* `deploy_app(version, environment)`
* `generate_test_report(format)`

Each function:

* Is explicitly defined
* Has a strict schema
* Limits possible parameters (whitelist)

## ğŸš€ Installation

### Prerequisites

* Python 3.12+
* GPU recommended (CPU possible but slower)

```bash
uv venv
source .venv/bin/activate
uv pip install -r requirements.txt
```

## â–¶ï¸ Running the Assistant

```bash
uv run python assistant.py
```

Then enter a natural language instruction:

```text
Run unit test in dev environment
Deploy version 1.2.3 to preprod
Generate test report in PDF
```

## ğŸ§ª Real Output Example

Internal model output:

```text
<start_function_call>
call:run_tests{type:<escape>unit<escape>,environment:<escape>dev<escape>}
<end_function_call>
```

Application interpretation:

```text
âœ… 'unit' tests launched on the 'dev' environment
```

## ğŸ›¡ï¸ Security & Reliability

* âœ… No direct execution from the LLM
* âœ… Actions limited to an authorized list
* âœ… Validated parameters
* âœ… Local model (no data leaks)
* âœ… Reproducible results

## ğŸ“ˆ Business Value

* â±ï¸ Operational time savings
* âŒ Reduction of human errors
* ğŸ§‘â€ğŸ¤â€ğŸ§‘ Autonomy for non-expert teams
* ğŸ” Better control over critical actions
* ğŸ’¸ Zero AI infrastructure costs

## ğŸ§  Lessons Learned

* Not all AI use cases **require** a giant LLM.
* The **instruction format** is as important as the model itself.
* Function calling is an excellent business interface.
* Local-first is often an advantage, not a constraint.

## ğŸ”® Future Roadmap

* `dry-run` mode
* Role management (QA / Dev / Admin)
* Logs & auditing
* CI/CD integration
* Web or Slack interface
* Fine-tuning on internal vocabulary

## ğŸ“£ Conclusion

This project demonstrates how to use an LLM **not to replace humans**, but to **simplify access to existing tools**.

ğŸ‘‰ The AI becomes the **interface**, not the decision-maker.
